name: Update RSS Feed

on:
  schedule:
    # Run twice daily at 6 AM and 6 PM UTC
    - cron: '0 6,18 * * *'
  workflow_dispatch: # Allow manual trigger
  push:
    branches:
      - main
      - master

permissions:
  contents: write

jobs:
  update-feed:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Fetch RSS Feed
        run: |
          # Retry logic for network resilience
          MAX_RETRIES=3
          RETRY_COUNT=0
          SUCCESS=false
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" = "false" ]; do
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "Attempt $RETRY_COUNT of $MAX_RETRIES to fetch RSS feed..."
            
            if curl -f -s --max-time 60 --connect-timeout 10 \
                https://www.cisa.gov/cybersecurity-advisories/all.xml > rss-feed.xml; then
              if [ -s rss-feed.xml ]; then
                echo "Successfully fetched RSS feed ($(wc -c < rss-feed.xml) bytes)"
                SUCCESS=true
              else
                echo "Warning: RSS feed is empty, retrying..."
                sleep 5
              fi
            else
              echo "Warning: Failed to fetch RSS feed, retrying in 5 seconds..."
              sleep 5
            fi
          done
          
          if [ "$SUCCESS" = "false" ]; then
            echo "Error: Failed to fetch RSS feed after $MAX_RETRIES attempts"
            exit 1
          fi

      - name: Parse RSS and Create JSON
        run: |
          python3 << 'EOF'
          import xml.etree.ElementTree as ET
          import json
          from datetime import datetime, timezone
          import sys
          import html

          def get_element_text(element, tag, default=''):
              """Safely extract text from an XML element."""
              try:
                  elem = element.find(tag)
                  if elem is not None:
                      # Handle both direct text and text with child elements
                      text = elem.text or ''
                      # Get text from all children (handles CDATA and mixed content)
                      for child in elem:
                          # Get text content of the child element itself
                          if child.text:
                              text += child.text
                          # Get tail text (text after the child element)
                          if child.tail:
                              text += child.tail
                      return text.strip() if text else default
                  return default
              except Exception as e:
                  print(f"Warning: Error extracting '{tag}': {e}")
                  return default

          try:
              print("Parsing RSS feed...")
              
              # Parse RSS feed with explicit encoding handling
              tree = ET.parse('rss-feed.xml')
              root = tree.getroot()
              
              # Detect RSS version and channel
              rss_version = root.attrib.get('version', 'unknown')
              print(f"RSS version: {rss_version}")
              
              # Find channel element (may or may not exist depending on RSS structure)
              channel = root.find('channel')
              if channel is None:
                  channel = root
                  print("Warning: No explicit channel element found, using root")
              
              # Extract channel metadata for debugging
              channel_title = get_element_text(channel, 'title', 'Unknown')
              print(f"Channel title: {channel_title}")

              # Find all items - try multiple xpaths for compatibility
              items_list = []
              for xpath in ['.//item', './channel/item', './item']:
                  items_list = root.findall(xpath)
                  if items_list:
                      print(f"Found {len(items_list)} items using xpath: {xpath}")
                      break
              
              if not items_list:
                  print("Error: No items found in RSS feed")
                  sys.exit(1)

              items = []
              for i, item in enumerate(items_list[:9], 1):  # Get only first 9 items
                  try:
                      title = get_element_text(item, 'title', f'Untitled Item {i}')
                      link = get_element_text(item, 'link', '')
                      description = get_element_text(item, 'description', '')
                      pubDate = get_element_text(item, 'pubDate', '')
                      
                      # Validate required fields
                      if not link:
                          print(f"Warning: Item {i} has no link, skipping")
                          continue
                      
                      # Unescape HTML entities in description
                      if description:
                          description = html.unescape(description)
                      
                      items.append({
                          'title': title,
                          'link': link,
                          'description': description,
                          'pubDate': pubDate
                      })
                      print(f"  Processed item {i}: {title[:60]}")
                      
                  except Exception as e:
                      print(f"Warning: Error processing item {i}: {e}")
                      continue

              if not items:
                  print("Error: No valid items found in RSS feed")
                  sys.exit(1)

              # Create JSON output
              feed_data = {
                  'items': items,
                  'lastUpdated': datetime.now(timezone.utc).isoformat(),
                  'source': 'CISA Cybersecurity Advisories',
                  'itemCount': len(items)
              }

              with open('feed-data.json', 'w', encoding='utf-8') as f:
                  json.dump(feed_data, f, indent=2, ensure_ascii=False)

              print(f"\nâœ“ Successfully processed {len(items)} feed items")
              
          except ET.ParseError as e:
              print(f"Error: Failed to parse XML - {e}")
              print("This may indicate malformed RSS feed or encoding issues")
              sys.exit(1)
          except FileNotFoundError:
              print("Error: rss-feed.xml not found")
              sys.exit(1)
          except Exception as e:
              print(f"Error: Unexpected error - {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          EOF

      - name: Commit and Push Feed Data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add feed-data.json
          git diff --staged --quiet || git commit -m "Update feed data - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
